\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{float}
\usepackage{bbm}
\input{Macros}
\usepackage{bm}
\usepackage{ upgreek }

\usepackage[]{mcode}
\usepackage{graphicx}
\usepackage{arydshln}
\begin{document}
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
\title{\Huge \textbf{STAT W4640 }\\
\Large\underline{Assignment One}
}%replace X with the appropriate number
\author{ \Large\textbf{Yicheng Wang}}
\maketitle
\section*{Chapter 1: Exercise 7}
There are three boxes: Box A, Box B, Box C. The probability of three box has the big prize will be: $$Pr(A)=Pr(B)=Pr(C)=\frac{1}{3}$$ Without the loss of generality,If Box A was chosen.
Let the Host Open Box C.The probability of the host opening the Box C will be: 
If A has the big prize, the host could open Box C or B: $Pr(Open C|A)=\frac{1}{2}$.If  B has the big prize,the host has to open Box C, $Pr(Open C|B)=1$. If C has the big prize, the host could never open Box C $Pr(Open C|C)=0$.
$$Pr(Open C)=\frac{1}{3}*(\frac{1}{2}+1+0)=\frac{1}{2}$$ 
Therefore,  the probability A has the big prize and the host open Box C will be:$$Pr(A|Open C)=\frac{Pr(Open C|A)Pr(A)}{Pr(Open C)}=\frac{\frac{1}{2}\cdot \frac{1}{3}}{\frac{1}{2}}=\frac{1}{3}$$ 
The probability B has the big prize and the host open Box C will be:$$Pr(B|Open C)=\frac{Pr(Open C|B)Pr(B)}{Pr(Open C)}=\frac{1\cdot \frac{1}{3}}{\frac{1}{2}}=\frac{2}{3}$$. After all, we suggest change the choice to the other unchosen box.
%Box A has the big prize and Box B,and C have the lesser prize. Probability of getting three boxes will be $$Pr(A)=Pr(B)=Pr(C)=\frac{1}{3}$$. Without the loss of generality, we suppose the guy chose box B. And the host open Box C. Pr(A|C)= 
%%Set A as the event of getting the box with fabulous prize, set $B_1$ as the event of getting one of the box with lesser prize, and set $B_2$ as the event of getting one of the box with lesser prize. As we know, $$Pr(A)=Pr(B_1)=Pr(B_2)$$
%Without losing the generality, we suppose the contestant got the $B_1$ box.
%
\section*{Computational Problem}
The prior density will be:$$p(\theta)= \frac{\alpha-\alpha^d}{1-\alpha}\cdot\frac{\theta}{\alpha}+\frac{1-\alpha}{1-\alpha^d}\cdot\theta $$
The likelihood function will be $$p(y|\theta)\propto \theta^y(1-\theta)^{n-y}$$
Therefore the posterior density will be: 
\begin{align*}
p(\theta|y)\propto p(y|\theta)\cdot p(\theta) &=\frac{1-\alpha^{d-1}}{1-\alpha}\cdot\theta^{1+y}(1-\theta)^{n-y}+\frac{1-\alpha}{1-\alpha^d}\cdot\theta^{1+y}(1-\theta)^{n-y}\\
&=\frac{(1-\alpha)^2+(1-\alpha^d)(1-\alpha^{d-1})}{(1-\alpha)(1-\alpha^d)}\theta^{1+y}(1-\theta)^{n-y}
\end{align*}
\section*{Chapter 2: Exercise 19}
\subsection*{(a)}
\begin{align*}
&p(\theta) \propto\ \theta^{\alpha-1}\exp(-\beta \theta)\\
&p(y|\theta) \propto \theta \exp(\theta y)\\
&p(\theta|y)\propto p(\theta)\cdot p(y|\theta)=\theta^{\alpha}\exp[(y-\beta)\theta]
\end{align*}
Therefore, the posterior density will have gamma distribution with $\alpha+1$ and $\beta-y$ two parameters. The posterior density and the prior density are both gamma distributed. Thus, we have conjugate prior distribution.
\subsection*{(b)}

\subsection*{(c)}
\subsection*{(d)}

\section*{Chapter 2: Exercise 21}
\subsection*{(a)}
\subsection*{(b)}
\subsection*{(c)}

\newpage
\section*{Problem 8.3}

\newpage
\section*{Problem 9.3}

%\section*{Problem 5.12}
%\subsection*{Answer for 5.12 (i)}
%We defined in 5.4.7 that $$B_i(t)=\sum_{j=1}^d \int_0^t \frac{\sigma_{ij}(u)}{\sigma_i(u)}dW_j(u)$$
%$$\gamma_i(t)=\sum_{j=1}^d \frac{\sigma_{ij}(t)\theta_j(t)}{\sigma_i(t)}$$
%$$\tilde B_i(t)=\sum_{j=1}^d \int_0^t(\frac{\sigma_{ij}(t)\theta_j(t)}{\sigma_i(t)}dW_j(u)+\gamma_i(u)du)$$
%Hence, $$d\tilde B_i(t)=$$
%\subsection*{Answer for 5.12 (ii)}
%\subsection*{Answer for 5.12 (iii)}
%\subsection*{Answer for 5.12 (iv)}
%\subsection*{Answer for 5.12 (v)}
%
%
%\section*{Problem 8.3}
%\section*{Problem 9.3}
%
%\subsection*{Answer for 5.1 (i)}
%Based on 5.2.19, $f(x)=S(0)\exp[x]$.
%$$dX(t)=\sigma(t)dW(t)+[\alpha(t)-R(t)-\frac{1}{2}\sigma^2(t)]dt$$
%$$D(t)S(t)=f(X(t))=S(0)\exp[\int_0^t \sigma(s)dW(s)+\int_0^t(\alpha(s)-R(s)-\frac{1}{2}\sigma^2(s))ds]$$
%\begin{align*}
%d (D(t)S(t))&=df(X(t))
%=\frac{\partial f}{\partial x}(t,X(t))dX(t)+\frac{1}{2}\frac{\partial^2 f}{\partial x^2}(t,X(t))dX(t)dX(t)\\
%&=f(X(t)) dX(t)+\frac{1}{2}f(X(t)) dX(t)dX(t)\\
%&=f(X(t))[dX(t)+\frac{1}{2}dX(t)dX(t)]\\
%&=f(X(t))[dX(t)+\frac{1}{2}\sigma^2(t)dt]\\
%&=f(X(t))[\sigma(t)dW(t)+[\alpha(t)-R(t)-\frac{1}{2}\sigma^2(t)]dt+\frac{1}{2}\sigma^2(t)dt]\\
%&=D(t)S(t)[\sigma(t)dW(t)+[\alpha(t)-R(t)]dt]\\
%&=D(t)S(t)\sigma(t)[\Theta(t)dt+dW(t)]
%\end{align*}
%%\begin{align*}
%%\intertext{Focusing on the right hand side of the equation}
%%d(D(t)S(t))&=S(t)dD(t)+D(t)dS(t)+dD(t)dS(t)\\
%%&=-S(t)R(t)D(t)dt+D(t)[\alpha S(t)dt+\sigma(t)S(t)dW(t)]+[R(t)D(t)dt][\alpha S(t)dt+\sigma(t)S(t)dW(t)]\\
%%&=-S(t)R(t)D(t)dt+D(t)[\alpha S(t)dt+\sigma(t)S(t)dW(t)]\\
%%&=[\alpha -R(t)]D(t)S(t)dt+\sigma(t)S(t)dW(t)]
%%\end{align*}
%\subsection*{Answer for 5.1 (ii)}
%\begin{align*}
%\intertext{Focusing on the right hand side of the equation}
%d(D(t)S(t))&=S(t)dD(t)+D(t)dS(t)+dD(t)dS(t)\\
%&=-S(t)R(t)D(t)dt+D(t)[\alpha S(t)dt+\sigma(t)S(t)dW(t)]+[R(t)D(t)dt][\alpha S(t)dt+\sigma(t)S(t)dW(t)]\\
%&=-S(t)R(t)D(t)dt+D(t)[\alpha S(t)dt+\sigma(t)S(t)dW(t)]\\
%&=[\alpha -R(t)]D(t)S(t)dt+\sigma(t)D(t)S(t)dW(t)]\quad \text{Because $\Theta(t)=\frac{\alpha -R(t)}{\sigma(t)}$}\\
%&=D(t)S(t)\sigma(t)[\Theta(t)dt+dW(t)]
%\end{align*}
%
%\section*{Problem 5.2}
%$$Z(t)=\exp\Big\{-\int_0^t\Theta(u)dW(u)-\frac{1}{2}\int_0^t\theta^2(u)du\Big\}$$
%$$D(t)=\exp[-\int_0^tR(s)ds]$$
%Since $D(T)V(T)$ is martingale under $\tilde{\bfE} $ risk neutral measure, then 
%$$D(t)V(t)=\tilde{\bfE}[D(T)V(T)|\mathcal{F}(t)]=E[D(T)V(T)Z(T)|\mathcal{F}(t)]/Z(t)$$
%After we organize the both side of the equation, we can get
%$$D(t)V(t)Z(t)=E[D(T)V(T)Z(T)|\mathcal{F}(t)]\quad \qed$$
%\section*{Problem 5.3}
%\subsection*{Answer for 5.3 (i) }
%if $S(T)>K,(S(T)-K)^+=S(T)-K$
%\begin{align*}
%c_x(0,x)=\frac{\partial c(0,x)}{\partial x}=\tilde{\bfE}[\exp(-rT)\cdot\exp(\sigma \tilde{W}(T)+rT-\frac{1}{2}\sigma^2T)]=\tilde{\bfE}[\exp(\sigma \tilde{W}(T)-\frac{1}{2}\sigma^2T)]
%\end{align*}
%
%if $S(T)<K,(S(T)-K)^+=0$
%\begin{align*}
%c_x(0,x)=0
%\end{align*}
%Therefore, 
%$$c_x(0,x)=\tilde{\bfE}[\exp(\sigma \tilde{W}(T)-\frac{1}{2}\sigma^2T) \mathbbm{1}_{S(T)>K}]=\tilde{\bfE}[\bar{Z}(T)\cdot  \mathbbm{1}_{S(T)>K}]$$
%
%
%\subsection*{Answer for 5.3 (ii) }
%We set new $\bar{P}$ measure, let  $$\bar{Z}(T)=\frac{d\bar{P}}{d\tilde{P}}$$
%Therefore, $$c_x(0,x)=\tilde{\bfE}[\bar{Z}(T)\cdot  \mathbbm{1}_{S(T)>K}]=\bar{E}[\frac{\bar{Z}(T)}{\bar{Z}(T)}\cdot  \mathbbm{1}_{S(T)>K}]=\bar{E}[ \mathbbm{1}_{S(T)>K}]=  \bar{P}[({S(T)-K})^+]\quad \qed$$
%%We know that $$
%%c(x,t)=xN(d_{+})-Ke^{-r(T-t)}N(d_{-}).$$
%%Therefore, $$\frac{\partial c(x,t)}{\partial x}=c_{x}=N(d_{+})+xN^{'}(d_{+})\frac{\partial d_{+}}{\partial x}-Ke^{-r(T-t)}N{'}(d_{-})\frac{\partial d_{-}}{\partial x}$$
%%$$\frac{\partial d_{+}}{\partial x}=\frac{\partial d_{-}}{\partial x}=\frac{1}{\sigma\sqrt{T-t}x}$$
%%By using the conclusion in the part (i), we can get: $$\frac{\partial c(x,t)}{\partial x}=c_{x}=N(d_{+})+0\cdot \frac{1}{\sigma\sqrt{T-t}x}=N(d_{+})$$
%%\begin{align*}
%%\frac{\partial c(x,t)}{\partial t}=c(x)=
%%\end{align*}
%\begin{align*}
%\bar{W}(t)&=\tilde{W}(t)-\sigma t=\tilde{W}(t)-\int_0^t\sigma du\\
%d[\bar{W}(t)\bar{Z}(t)]&=d\bar{W}(t)\bar{Z}(t)+\bar{W}(t)d\bar{Z}(t)+f\bar{Z}(t)d\bar{W}(t)\\
%&=(-\bar{W}(t)\sigma+1)\bar{Z}(t)d\tilde{W}(t)\\
%\intertext{Since there is no $dt$ term, the process is a martingale under $\bar{P}$ } 
%\bar{E}[\bar{W}(t)|\mathcal{F}(s)]&=\frac{\tilde{E}[\bar{W}(t)\bar{Z}(t)|\mathcal{F}(s)]}{\bar{Z}(s)}=\frac{\bar{W}(s)\bar{Z}(s)}{\bar{Z}(s)}=\bar{W}(s) \qed
%\end{align*}
%\subsection*{Answer for 5.3 (iii) }
%\begin{align*}
%\bar{P}(S(T)>K)&=\bar{P}[x\Big(\exp(\sigma \tilde{W}(T)+(r-\frac{1}{2}\sigma^2)T)\Big)>K]=\bar{P}[x\Big(\exp(\sigma \bar{W}(T)+(r+\frac{1}{2}\sigma^2)T)\Big)>K]\\
%&=\bar{P}[ \bar{W}(T)>\frac{1}{\sigma}\Big(\ln\frac{ K}{x}-(r+\frac{1}{2}\sigma^2) T\Big)]\\
%&=\bar{P}[ -\frac{\bar{W}(T)}{\sqrt{T}}<\frac{1}{\sigma\sqrt{T}} \Big(\ln\frac{ x}{K}+(r+\frac{1}{2}\sigma^2) T\Big)]=N(d_{+}(T,x)) \qed
%\end{align*}
%\section*{Problem 5.4}
%\subsection*{Answer for 5.4 (i)}
%$$dS(t)=r(t)S(t)dt+\sigma(t)S(t)d\tilde{W}(t)$$
%\begin{align*}
%d\ln[S(t)]&=\frac{\partial \ln[S(t)]}{\partial x}dS(t)+\frac{1}{2}\frac{\partial^2 \ln[S(t)]}{\partial x^2}dS(t)dS(t)\\
%&=\frac{1}{S(t)}dS(t)-\frac{1}{2}(\frac{1}{S(t)})^2dS(t)dS(t)\\
%&=r(t)dt+\sigma(t)d\tilde{W}(t)-\frac{1}{2}\sigma^2 dt
%\end{align*}
%Therefore,$$\ln S(T)-\ln S(0)=\int_0^T\Big(r(t)-\frac{1}{2}\sigma^2\Big)dt+\int_0^T\sigma(t)d\tilde{W}(t)$$
%$$S(T)=S(0)\exp\Big[\int_0^T\Big(r(t)-\frac{1}{2}\sigma^2\Big)dt+\int_0^T\sigma(t)d\tilde{W}(t)\Big]$$
%
%\subsection*{Answer for 5.4 (ii)}
%According to what we have in the previous problem, 
%%Therefore,
%\begin{align*}
%c(0,S(0))&=\exp[-\int_0^Tr(t)dt]\tilde{E}[(S(T)-K)^{+}]\\
%\end{align*}
%We let $$T(R+\frac{1}{2}\Sigma^2)=\int_0^T r(t)dt+\frac{1}{2}\int_0^T\sigma^2(t)dt$$
%$$T(R-\frac{1}{2}\Sigma^2)=\int_0^T r(t)dt-\frac{1}{2}\int_0^T\sigma^2(t)dt$$
%
%\begin{align*}
%\tilde{E}[(S(T)-K)^{+}]&=\tilde{E}[\Big(S(0)\exp\Big[\int_0^T\Big(r(t)-\frac{1}{2}\sigma^2(t)\Big)dt+\int_0^T\sigma(t)d\tilde{W}(t)\Big]-K\Big)^+]\\
%&=\tilde{E}[\Big(S(0)\exp\Big[(R-\frac{1}{2}\Sigma^2)T+\Sigma \tilde{W}(t)\Big]-K\Big)^+]\\
%&=\exp[RT]BSM(T,S(0);K,R,\Sigma)\\
%\end{align*}
%Therefore,
%\begin{align*}
%c(0,S(0))&=\exp[-\int_0^Tr(t)dt]\tilde{E}[(S(T)-K)^{+}]\\
%&=\exp[-\int_0^Tr(t)dt]\exp[RT]BSM(T,S(0);K,R,\Sigma)\\
%&=BSM(T,S(0);K,R,\Sigma)\\
%&=BSM\Big(T,S(0);K,\frac{1}{T}\int_0^T r(t)dt,\sqrt{\frac{1}{T}\int_0^T\sigma^2(t)dt}\Big)
%\end{align*}
%
%After rebalancing, $$X(t+1)=\Delta(t+1)S(t+1)+\Gamma(t+1)M(t+1)$$
%By setting those two $X(t+1)$ equal, we can get$$ d\Delta(t)S(t+1)+d\Gamma(t)M(t+1)=0$$
%Then we can get $$S(t)d\Delta(t)+d\Delta(t)dS(t)+\Gamma(t)dM(t)+d\Gamma(t)dM(t)=0$$
\end{document}